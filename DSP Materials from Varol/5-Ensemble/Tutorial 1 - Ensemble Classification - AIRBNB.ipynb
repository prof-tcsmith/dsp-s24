{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - Ensemble - Classification\n",
    "\n",
    "\n",
    "We will predict the price category, among 4 categories, of an AIRBNB listing (`price_category` column). This is a multi-class classification task.\n",
    "\n",
    "**The unit of analysis is an AIRBNB LISTING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will predict the \"price_gte_150\" value in the data set:\n",
    "\n",
    "airbnb = pd.read_csv(\"airbnb.csv\")\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(airbnb, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be careful: we haven't seperated the target column yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the variables we can't use in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't use the following columns in this tutorial, because they are not for binary classification tasks\n",
    "\n",
    "train = train_set.drop(['price', 'price_gte_150'], axis=1)\n",
    "test = test_set.drop(['price', 'price_gte_150'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the target variable (we don't want to transform it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['price_category']\n",
    "test_y = test['price_category']\n",
    "\n",
    "train_inputs = train.drop(['price_category'], axis=1)\n",
    "test_inputs = test.drop(['price_category'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Let's derive a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the `number of reviews` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs['number_of_reviews'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs['number_of_reviews'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new ordinal column: convert the number of reviews to ordinal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_col(df):\n",
    "    #Create a copy so that we don't overwrite the existing dataframe\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    df1['num_reviews_binned'] = pd.cut(df1['number_of_reviews'],\n",
    "                                       bins=[0,0.5,1,5,15,50,10000],  #bins=[exclusive, inclusive]\n",
    "                                       labels=False, \n",
    "                                       include_lowest=True,\n",
    "                                       ordered=True)\n",
    "    \n",
    "#     You can also do this if you want categorical values:    \n",
    "#     df1['num_reviews_binned'] = pd.cut(df1['number_of_reviews'],\n",
    "#                                        bins=[0,0.5,1,5,15,50,10000], \n",
    "#                                        labels=['None','Very few','Few','Medium','Many','Too many'], \n",
    "#                                        include_lowest=True,\n",
    "#                                        ordered=False)\n",
    "\n",
    "    \n",
    "    return df1[['num_reviews_binned']]\n",
    "    # You can use this to check whether the calculation is made correctly:\n",
    "    #return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's test the new function:\n",
    "\n",
    "# Send train set to the function we created\n",
    "new_col(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the new distribution\n",
    "\n",
    "new_col(train_set).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Identify the numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this stage, you can manually identify numeric, binary, and categorical columns as follows:**\n",
    "\n",
    "`numeric_columns = ['latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'Number of amenities', 'guests_included', 'price_per_extra_person', 'minimum_nights', 'number_of_reviews', 'number_days_btw_first_last_review', 'review_scores_rating']`\n",
    " \n",
    " `binary_columns = ['host_is_superhost', 'host_identity_verified']`\n",
    " \n",
    " `categorical_columns = ['neighbourhood_cleansed', 'property_type', 'room_type', 'bed_type', 'cancellation_policy']`\n",
    " \n",
    "<br>\n",
    " \n",
    "**If you do not want to manually type these, you can do the below tricks:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the binary columns so we can pass them through without transforming\n",
    "binary_columns = ['host_is_superhost', 'host_identity_verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful: numerical columns already includes the binary columns,\n",
    "# So, we need to remove the binary columns from numerical columns.\n",
    "\n",
    "for col in binary_columns:\n",
    "    numeric_columns.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_eng_columns = ['number_of_reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_column = Pipeline(steps=[('my_new_column', FunctionTransformer(new_col)),\n",
    "                               ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('binary', binary_transformer, binary_columns),\n",
    "        ('trans', my_new_column, feat_eng_columns)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform: fit_transform() for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dummy_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline Train Accuracy\n",
    "dummy_train_pred = dummy_clf.predict(train_x)\n",
    "\n",
    "baseline_train_acc = accuracy_score(train_y, dummy_train_pred)\n",
    "\n",
    "print('Baseline Train Accuracy: {}' .format(baseline_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline Test Accuracy\n",
    "dummy_test_pred = dummy_clf.predict(test_x)\n",
    "\n",
    "baseline_test_acc = accuracy_score(test_y, dummy_test_pred)\n",
    "\n",
    "print('Baseline Test Accuracy: {}' .format(baseline_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "dtree_clf = DecisionTreeClassifier(max_depth=20)\n",
    "log_clf = LogisticRegression(multi_class='multinomial', solver = 'lbfgs', C=10, max_iter=1000)\n",
    "sgd_clf = SGDClassifier(max_iter=10000, tol=1e-3)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "            estimators=[('dt', dtree_clf), \n",
    "                        ('lr', log_clf), \n",
    "                        ('sgd', sgd_clf)],\n",
    "            voting='hard')\n",
    "\n",
    "voting_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = voting_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = voting_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect each classifier's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in (dtree_clf, log_clf, sgd_clf, voting_clf):\n",
    "    clf.fit(train_x, train_y.ravel())\n",
    "    test_y_pred = clf.predict(test_x)\n",
    "    print(clf.__class__.__name__, 'Test acc=', accuracy_score(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard voting with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_clf = DecisionTreeClassifier(max_depth=20)\n",
    "log_clf = LogisticRegression(multi_class='multinomial', solver = 'lbfgs', C=10, max_iter=1000)\n",
    "sgd_clf = SGDClassifier(max_iter=10000, tol=1e-3)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "            estimators=[('dt', dtree_clf), \n",
    "                        ('lr', log_clf), \n",
    "                        ('sgd', sgd_clf)],\n",
    "            voting='hard',\n",
    "            weights=[0.6, 0.2, 0.2])\n",
    "\n",
    "voting_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = voting_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = voting_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each model should have predict_proba() function. Otherwise, you can't use it for soft voting\n",
    "#We can't use sgd, because it doesn't have predict_proba() function.\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "            estimators=[('dt', dtree_clf), \n",
    "                        ('lr', log_clf)],\n",
    "            voting='soft')\n",
    "\n",
    "voting_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = voting_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = voting_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier \n",
    "\n",
    "\n",
    "#If you want to do pasting, change \"bootstrap=False\"\n",
    "#n_jobs=-1 means use all CPU cores\n",
    "#bagging automatically performs soft voting\n",
    "\n",
    "bag_clf = BaggingClassifier( \n",
    "            SGDClassifier(), n_estimators=50, \n",
    "            max_samples=1000, bootstrap=True, n_jobs=-1) \n",
    "\n",
    "bag_clf.fit(train_x, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = bag_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = bag_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Patches: see the max_features variable\n",
    "bag_clf = BaggingClassifier( \n",
    "            SGDClassifier(), n_estimators=50, max_features=10,\n",
    "            max_samples=1000, bootstrap=True, n_jobs=-1) \n",
    "\n",
    "bag_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = bag_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = bag_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Subspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Random subspaces: see the max_samples variable\n",
    "bag_clf = BaggingClassifier( \n",
    "            SGDClassifier(), n_estimators=50, max_features=10,\n",
    "            max_samples=len(train_x), bootstrap=True, n_jobs=-1) \n",
    "\n",
    "bag_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = bag_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = bag_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1) \n",
    "\n",
    "rnd_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = rnd_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = rnd_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnd_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round to two decimals\n",
    "np.round(rnd_clf.feature_importances_,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra-Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "\n",
    "ext_clf = ExtraTreesClassifier(n_estimators=500,  n_jobs=-1) \n",
    "\n",
    "ext_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = ext_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = ext_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "\n",
    "#Create Adapative Boosting with Decision Stumps (depth=1)\n",
    "ada_clf = AdaBoostClassifier( \n",
    "            DecisionTreeClassifier(max_depth=1), n_estimators=500, \n",
    "            learning_rate=0.1) \n",
    "\n",
    "\n",
    "ada_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = ada_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = ada_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use GradientBoosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbclf = GradientBoostingClassifier(max_depth=2, n_estimators=100, learning_rate=0.1) \n",
    "\n",
    "gbclf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = gbclf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = gbclf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train on 75% of the sample only\n",
    "\n",
    "gbclf = GradientBoostingClassifier(max_depth=2, n_estimators=100, \n",
    "                                   learning_rate=0.1, subsample=0.75) \n",
    "\n",
    "gbclf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = gbclf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = gbclf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in range(1,30):\n",
    "    gbclf = GradientBoostingClassifier(max_depth=3, n_estimators=x, learning_rate=1.0) \n",
    "    gbclf.fit(train_x, train_y.ravel())\n",
    "    \n",
    "    train_predictions = gbclf.predict(train_x)\n",
    "    test_predictions = gbclf.predict(test_x)\n",
    "    \n",
    "    train_accuracy = round(accuracy_score(train_y, train_predictions),4)\n",
    "    test_accuracy = round(accuracy_score(test_y, test_predictions),4)\n",
    "    \n",
    "    print('# Estimators = {}'.format(x) + \"     \" + 'Train accuracy = {}'.format(train_accuracy) + \"   \"\n",
    "         'Test accuracy = {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notice that learning rate and tol are high to see early stopping\n",
    "gbclf = GradientBoostingClassifier(max_depth=2, n_estimators=100, \n",
    "                                   learning_rate=1, \n",
    "                                  tol=0.1, n_iter_no_change=5, validation_fraction=0.2,\n",
    "                                  verbose=1) \n",
    "\n",
    "gbclf.fit(train_x, train_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbclf.n_estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = gbclf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = gbclf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, start Anaconda Command Prompt, and type `pip install xgboost` to install XGBoost. Otherwise, default Anaconda installation doesn't include XGBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgboost.XGBClassifier()\n",
    "\n",
    "xgb_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = xgb_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = xgb_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
