{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will focus on underage drinking. The data set contains data about high school students. Each row represents a single student. The columns include the characteristics of deidentified students. This is a binary classification task: predict whether a student drinks alcohol or not (this is the **alc** column: 1=Yes, 0=No). This is an important prediction task to detect underage drinking and deploy intervention techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "The description of variables are provided in \"Alcohol - Data Dictionary.docx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the **alcohol.csv** data set and build a model to predict **alc**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>gender</th>\n",
       "      <th>alc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     2     1           4          2         0       5         4      2   \n",
       "1   18     4     3           1          0         0       4         4      2   \n",
       "2   15     4     3           2          3         0       5         3      4   \n",
       "3   15     3     3           1          4         0       4         3      3   \n",
       "4   17     3     2           1          2         0       5         3      5   \n",
       "\n",
       "   health  absences gender  alc  \n",
       "0       5         2      M    1  \n",
       "1       3         9      M    1  \n",
       "2       5         0      F    0  \n",
       "3       3        10      F    0  \n",
       "4       5         2      M    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will predict the \"price\" value in the data set:\n",
    "\n",
    "alcohol = pd.read_csv(\"alcohol.csv\")\n",
    "alcohol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alc\n",
       "0    17757\n",
       "1    16243\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Identify any issues with data imbalance\n",
    "\n",
    "alcohol['alc'].value_counts() # we can see that these are a bit imbalanced, but nothing to be too concerned about. If the imbalance was greater, use one of the techniques to balance the data that we discussed in data mining.\n",
    "\n",
    "\n",
    "# If you had not seen how to address data imbalance, you would do this only on the test set (so later on in this code). See the section later in this document. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Derive a new column\n",
    "\n",
    "Examples:\n",
    "- Ratio of study time to travel time\n",
    "- Student is younger than 18 or not\n",
    "- Average of father's and mother's level of education\n",
    "- (etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>gender</th>\n",
       "      <th>alc</th>\n",
       "      <th>study_2_travel</th>\n",
       "      <th>younger_than_18</th>\n",
       "      <th>avg_edu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     2     1           4          2         0       5         4      2   \n",
       "1   18     4     3           1          0         0       4         4      2   \n",
       "2   15     4     3           2          3         0       5         3      4   \n",
       "3   15     3     3           1          4         0       4         3      3   \n",
       "4   17     3     2           1          2         0       5         3      5   \n",
       "\n",
       "   health  absences gender  alc  study_2_travel  younger_than_18  avg_edu  \n",
       "0       5         2      M    1             0.5                0      1.5  \n",
       "1       3         9      M    1             0.0                0      3.5  \n",
       "2       5         0      F    0             1.5                1      3.5  \n",
       "3       3        10      F    0             4.0                1      3.0  \n",
       "4       5         2      M    1             2.0                1      2.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol['study_2_travel'] = (alcohol['studytime'] / alcohol['traveltime']).replace([np.inf, -np.inf], np.nan)\n",
    "alcohol['younger_than_18'] = (alcohol['age'] < 18).astype(int)\n",
    "alcohol['avg_edu'] = (alcohol['Medu'] + alcohol['Fedu']) / 2\n",
    "\n",
    "alcohol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>study_2_travel</th>\n",
       "      <th>younger_than_18</th>\n",
       "      <th>avg_edu</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>alc_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     2     1           4          2         0       5         4      2   \n",
       "1   18     4     3           1          0         0       4         4      2   \n",
       "2   15     4     3           2          3         0       5         3      4   \n",
       "3   15     3     3           1          4         0       4         3      3   \n",
       "4   17     3     2           1          2         0       5         3      5   \n",
       "\n",
       "   health  absences  study_2_travel  younger_than_18  avg_edu  gender_M  alc_1  \n",
       "0       5         2             0.5                0      1.5         1      1  \n",
       "1       3         9             0.0                0      3.5         1      1  \n",
       "2       5         0             1.5                1      3.5         0      0  \n",
       "3       3        10             4.0                1      3.0         0      0  \n",
       "4       5         2             2.0                1      2.5         1      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode gender M and F to 1 and 0 respectively\n",
    "\n",
    "alcohol = pd.get_dummies(alcohol, columns=['gender', 'alc'], drop_first=True, dtype='int')\n",
    "\n",
    "alcohol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>study_2_travel</th>\n",
       "      <th>younger_than_18</th>\n",
       "      <th>avg_edu</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>alc_use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     2     1           4          2         0       5         4      2   \n",
       "1   18     4     3           1          0         0       4         4      2   \n",
       "2   15     4     3           2          3         0       5         3      4   \n",
       "3   15     3     3           1          4         0       4         3      3   \n",
       "4   17     3     2           1          2         0       5         3      5   \n",
       "\n",
       "   health  absences  study_2_travel  younger_than_18  avg_edu  gender_M  \\\n",
       "0       5         2             0.5                0      1.5         1   \n",
       "1       3         9             0.0                0      3.5         1   \n",
       "2       5         0             1.5                1      3.5         0   \n",
       "3       3        10             4.0                1      3.0         0   \n",
       "4       5         2             2.0                1      2.5         1   \n",
       "\n",
       "   alc_use  \n",
       "0        1  \n",
       "1        1  \n",
       "2        0  \n",
       "3        0  \n",
       "4        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol = alcohol.rename(columns={'alc_1': 'alc_use'})\n",
    "\n",
    "alcohol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "\n",
    "y = alcohol['alc_use']\n",
    "X = alcohol.drop('alc_use', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Identify the numeric, binary, and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = X.select_dtypes('number').columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = X.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'famrel',\n",
       " 'freetime',\n",
       " 'goout',\n",
       " 'health',\n",
       " 'absences',\n",
       " 'study_2_travel',\n",
       " 'younger_than_18',\n",
       " 'avg_edu',\n",
       " 'gender_M']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['younger_than_18', 'gender_M']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns = [col for col in X.columns if X[col].nunique() == 2]\n",
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'famrel',\n",
       " 'freetime',\n",
       " 'goout',\n",
       " 'health',\n",
       " 'absences',\n",
       " 'study_2_travel',\n",
       " 'avg_edu']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for binary_col in binary_columns:\n",
    "    numeric_columns.remove(binary_col)\n",
    "    \n",
    "numeric_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address any data imbalance issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> See presentation for more details on the pros and cons of each technique. It's up to you to decide which one to use, and justify why you chose it. Another approach would be to train the models on resampled data using each of the 4 techniques and report which approach resulted in the best outcome. Also, it's important to note that you should not resample the test data, only the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# There are three main techniques to balance the data (see powerpoint presentation for more details on these techniques):\n",
    "# 1. Random Over Sampling\n",
    "# 2. Random Under Sampling\n",
    "# 3. SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "# 4. ADASYN (Adaptive Synthetic Sampling)\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "# rus = RandomUnderSampler(random_state=0)\n",
    "# smote = SMOTE(random_state=0)\n",
    "# adasyn = ADASYN(random_state=0)\n",
    "\n",
    "# X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "# X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "# X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=-1)),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline( steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns), # we don't have any categorical columns in this data set, so we don't need to include this line\n",
    "        ('binary', binary_transformer, binary_columns)        \n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform: fit_transform() for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and transform the train data\n",
    "X_train = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23800, 15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23984621,  0.33104402,  1.76705606, ...,  1.01168573,\n",
       "         1.        ,  0.        ],\n",
       "       [-1.23984621, -0.30388608,  0.04019664, ..., -0.1702172 ,\n",
       "         1.        ,  1.        ],\n",
       "       [-0.28670367,  0.33104402,  0.04019664, ...,  0.22375045,\n",
       "         1.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 0.66643886, -0.30388608,  0.04019664, ..., -0.1702172 ,\n",
       "         1.        ,  0.        ],\n",
       "       [-1.23984621, -0.93881619,  0.04019664, ..., -0.56418484,\n",
       "         1.        ,  1.        ],\n",
       "       [-1.23984621,  0.96597412,  0.04019664, ...,  0.61771809,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10200, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe to store results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "results = pd.DataFrame(columns=['Model', 'Duration', 'Accuracy', 'Precision', 'Recall', 'F1', 'AUC', 'Best Parameters'])\n",
    "\n",
    "iters = 5\n",
    "folds = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Logistic Regress Classifier (use random search hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.702046</td>\n",
       "      <td>0.821373</td>\n",
       "      <td>0.822446</td>\n",
       "      <td>0.801306</td>\n",
       "      <td>0.811738</td>\n",
       "      <td>0.820623</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Duration  Accuracy  Precision    Recall        F1  \\\n",
       "0  Logistic Regression  0.702046  0.821373   0.822446  0.801306  0.811738   \n",
       "\n",
       "        AUC                                                    Best Parameters  \n",
       "0  0.820623  {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# setup parameters for RandomizedSearchCV for Logistic Regression\n",
    "param_distributions = {\n",
    "    'C': np.logspace(-4, 4, 100),\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg_cv = RandomizedSearchCV(log_reg, param_distributions, n_iter=iters, cv=folds, scoring='f1', verbose=1, n_jobs=-1, random_state=42)\n",
    "log_reg_cv.fit(X_train, y_train)\n",
    "model01 = log_reg_cv.best_estimator_\n",
    "\n",
    "# calculate accuracy, precision, recall, f1, auc\n",
    "y_pred = model01.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "# Pandas used to have a append method, but it is now deprecated. The recommended way is to use the concat method or the following method:\n",
    "results.loc[len(results.index)] = ['Logistic Regression', end-start, accuracy, precision, recall, f1, auc, str(log_reg_cv.best_params_)]\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a random forest classifier (use random search hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.702046</td>\n",
       "      <td>0.821373</td>\n",
       "      <td>0.822446</td>\n",
       "      <td>0.801306</td>\n",
       "      <td>0.811738</td>\n",
       "      <td>0.820623</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>8.487113</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.812706</td>\n",
       "      <td>0.803754</td>\n",
       "      <td>0.808205</td>\n",
       "      <td>0.816184</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Duration  Accuracy  Precision    Recall        F1  \\\n",
       "0  Logistic Regression  0.702046  0.821373   0.822446  0.801306  0.811738   \n",
       "1        Random Forest  8.487113  0.816667   0.812706  0.803754  0.808205   \n",
       "\n",
       "        AUC  \\\n",
       "0  0.820623   \n",
       "1  0.816184   \n",
       "\n",
       "                                                                                                                     Best Parameters  \n",
       "0                                                                  {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}  \n",
       "1  {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# set up parameters for RandomizedSearchCV for Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=200, stop=2000, num=10)],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [int(x) for x in np.linspace(2, 100, num=2)] + [None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_cv = RandomizedSearchCV(rf, param_distributions, n_iter=iters, cv=folds, scoring='f1', verbose=1, n_jobs=-1, random_state=42)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "model02 = rf_cv.best_estimator_\n",
    "\n",
    "# calculate accuracy, precision, recall, f1, auc\n",
    "y_pred = model02.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "results.loc[len(results.index)] = ['Random Forest', end-start, accuracy, precision, recall, f1, auc, str(rf_cv.best_params_)]\n",
    "\n",
    "results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an adaboost classifier (use random search hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.702046</td>\n",
       "      <td>0.821373</td>\n",
       "      <td>0.822446</td>\n",
       "      <td>0.801306</td>\n",
       "      <td>0.811738</td>\n",
       "      <td>0.820623</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>8.487113</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.812706</td>\n",
       "      <td>0.803754</td>\n",
       "      <td>0.808205</td>\n",
       "      <td>0.816184</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>6.462828</td>\n",
       "      <td>0.826078</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.811710</td>\n",
       "      <td>0.817715</td>\n",
       "      <td>0.825541</td>\n",
       "      <td>{'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Duration  Accuracy  Precision    Recall        F1  \\\n",
       "0  Logistic Regression  0.702046  0.821373   0.822446  0.801306  0.811738   \n",
       "1        Random Forest  8.487113  0.816667   0.812706  0.803754  0.808205   \n",
       "2             AdaBoost  6.462828  0.826078   0.823810  0.811710  0.817715   \n",
       "\n",
       "        AUC  \\\n",
       "0  0.820623   \n",
       "1  0.816184   \n",
       "2  0.825541   \n",
       "\n",
       "                                                                                                                     Best Parameters  \n",
       "0                                                                  {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}  \n",
       "1  {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}  \n",
       "2                                      {'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# set up parameters for RandomizedSearchCV for adabooost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_distributions = {\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), DecisionTreeClassifier(max_depth=3), DecisionTreeClassifier(max_depth=4)],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "ada_cv = RandomizedSearchCV(ada, param_distributions, n_iter=iters, cv=folds, scoring='f1', verbose=1, n_jobs=-1, random_state=42)\n",
    "ada_cv.fit(X_train, y_train)\n",
    "model03 = ada_cv.best_estimator_\n",
    "\n",
    "# calculate accuracy, precision, recall, f1, auc\n",
    "y_pred = model03.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "results.loc[len(results.index)] = ['AdaBoost', end-start, accuracy, precision, recall, f1, auc, str(ada_cv.best_params_)]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.702046</td>\n",
       "      <td>0.821373</td>\n",
       "      <td>0.822446</td>\n",
       "      <td>0.801306</td>\n",
       "      <td>0.811738</td>\n",
       "      <td>0.820623</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>8.487113</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.812706</td>\n",
       "      <td>0.803754</td>\n",
       "      <td>0.808205</td>\n",
       "      <td>0.816184</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>6.462828</td>\n",
       "      <td>0.826078</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.811710</td>\n",
       "      <td>0.817715</td>\n",
       "      <td>0.825541</td>\n",
       "      <td>{'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2.696353</td>\n",
       "      <td>0.809118</td>\n",
       "      <td>0.808133</td>\n",
       "      <td>0.790494</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.808422</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Duration  Accuracy  Precision    Recall        F1  \\\n",
       "0  Logistic Regression  0.702046  0.821373   0.822446  0.801306  0.811738   \n",
       "1        Random Forest  8.487113  0.816667   0.812706  0.803754  0.808205   \n",
       "2             AdaBoost  6.462828  0.826078   0.823810  0.811710  0.817715   \n",
       "3                  KNN  2.696353  0.809118   0.808133  0.790494  0.799216   \n",
       "\n",
       "        AUC  \\\n",
       "0  0.820623   \n",
       "1  0.816184   \n",
       "2  0.825541   \n",
       "3  0.808422   \n",
       "\n",
       "                                                                                                                     Best Parameters  \n",
       "0                                                                  {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}  \n",
       "1  {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}  \n",
       "2                                      {'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}  \n",
       "3                                                             {'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up parameters for RandomizedSearchCV for KNN  (this is a slow process)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_distributions = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_cv = RandomizedSearchCV(knn, param_distributions, n_iter=iters, cv=folds, scoring='f1', verbose=1, n_jobs=-1, random_state=42)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "model04 = knn_cv.best_estimator_\n",
    "\n",
    "# calculate accuracy, precision, recall, f1, auc\n",
    "y_pred = model04.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "end = time.time()\n",
    "results.loc[len(results.index)] = ['KNN', end-start, accuracy, precision, recall, f1, auc, str(knn_cv.best_params_)]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.702046</td>\n",
       "      <td>0.821373</td>\n",
       "      <td>0.822446</td>\n",
       "      <td>0.801306</td>\n",
       "      <td>0.811738</td>\n",
       "      <td>0.820623</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>8.487113</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.812706</td>\n",
       "      <td>0.803754</td>\n",
       "      <td>0.808205</td>\n",
       "      <td>0.816184</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>6.462828</td>\n",
       "      <td>0.826078</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.811710</td>\n",
       "      <td>0.817715</td>\n",
       "      <td>0.825541</td>\n",
       "      <td>{'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2.696353</td>\n",
       "      <td>0.809118</td>\n",
       "      <td>0.808133</td>\n",
       "      <td>0.790494</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.808422</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>3.602068</td>\n",
       "      <td>0.827059</td>\n",
       "      <td>0.824710</td>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.818780</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>{'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 1000, 'max_depth': None, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.75}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Duration  Accuracy  Precision    Recall        F1  \\\n",
       "0  Logistic Regression  0.702046  0.821373   0.822446  0.801306  0.811738   \n",
       "1        Random Forest  8.487113  0.816667   0.812706  0.803754  0.808205   \n",
       "2             AdaBoost  6.462828  0.826078   0.823810  0.811710  0.817715   \n",
       "3                  KNN  2.696353  0.809118   0.808133  0.790494  0.799216   \n",
       "4        XGBClassifier  3.602068  0.827059   0.824710  0.812933  0.818780   \n",
       "\n",
       "        AUC  \\\n",
       "0  0.820623   \n",
       "1  0.816184   \n",
       "2  0.825541   \n",
       "3  0.808422   \n",
       "4  0.826531   \n",
       "\n",
       "                                                                                                                                             Best Parameters  \n",
       "0                                                                                          {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}  \n",
       "1                          {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}  \n",
       "2                                                              {'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}  \n",
       "3                                                                                     {'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}  \n",
       "4  {'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 1000, 'max_depth': None, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.75}  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up parameters for RandomizedSearchCV for XGBClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=200, stop=2000, num=10)],\n",
    "    'max_depth': [int(x) for x in np.linspace(2, 100, num=2)] + [None],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
    "    'subsample': [0.5, 0.75, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.75, 1.0],\n",
    "    'gamma': [0, 1, 5],\n",
    "    'reg_alpha': [0, 1, 5],\n",
    "    'reg_lambda': [0, 1, 5]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb_cv = RandomizedSearchCV(xgb, param_distributions, n_iter=iters, cv=folds, scoring='f1', verbose=1, n_jobs=-1, random_state=42)\n",
    "xgb_cv.fit(X_train, y_train)\n",
    "model05 = xgb_cv.best_estimator_\n",
    "\n",
    "# calculate accuracy, precision, recall, f1, auc\n",
    "y_pred = model05.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "results.loc[len(results.index)] = ['XGBClassifier', end-start, accuracy, precision, recall, f1, auc, str(xgb_cv.best_params_)]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC\n",
    "\n",
    "Uncomment the code below to train a SVC model. This model is computationally expensive and may take a long time to train. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# set up parameters for RandomizedSearchCV for SVM  (this is a slow process)\\n\\nstart = time.time()\\n\\nfrom sklearn.svm import SVC\\n\\nparam_distributions = {\\n    'C': [0.1, 1, 2, 5, 10, 15, 20, 40, 80, 100],\\n    'gamma': [1, 0.5, 0.1, 0.05, 0.01, 0.001],\\n    'kernel': ['rbf', 'poly', 'sigmoid']\\n}\\n\\nsvc = SVC()\\n\\nsvc_cv = RandomizedSearchCV(svc, param_distributions, n_iter=iters, cv=folds, scoring='f1', verbose=1, n_jobs=-1, random_state=42)\\n\\nsvc_cv.fit(X_train, y_train)\\nmodel06 = svc_cv.best_estimator_\\n\\n# calculate accuracy, precision, recall, f1, auc\\ny_pred = model06.predict(X_test)\\n\\naccuracy = accuracy_score(y_test, y_pred)\\nprecision = precision_score(y_test, y_pred, zero_division=0)\\nrecall = recall_score(y_test, y_pred, zero_division=0)\\nf1 = f1_score(y_test, y_pred, zero_division=0)\\nauc = roc_auc_score(y_test, y_pred)\\n\\nend = time.time()\\n\\nresults.loc[len(results.index)] = ['SVM', end-start, accuracy, precision, recall, f1, auc, str(svc_cv.best_params_)]\\nresults\\n\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "# set up parameters for RandomizedSearchCV for SVM  (this is a slow process)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_distributions = {\n",
    "    'C': [0.1, 1, 2, 5, 10, 15, 20, 40, 80, 100],\n",
    "    'gamma': [1, 0.5, 0.1, 0.05, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc_cv = RandomizedSearchCV(svc, param_distributions, n_iter=iters, cv=folds, scoring='f1', verbose=1, n_jobs=-1, random_state=42)\n",
    "\n",
    "svc_cv.fit(X_train, y_train)\n",
    "model06 = svc_cv.best_estimator_\n",
    "\n",
    "# calculate accuracy, precision, recall, f1, auc\n",
    "y_pred = model06.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "results.loc[len(results.index)] = ['SVM', end-start, accuracy, precision, recall, f1, auc, str(svc_cv.best_params_)]\n",
    "results\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Voting Classifier using previous models (test both soft and hard voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Voting\n",
    "\n",
    "This is the default behavior of the VotingClassifier. In hard voting, the predicted output class is a class with the highest majority of votes i.e the class which had the highest probability of being predicted by each of the classifiers. Suppose three classifiers predicted the output class(A, A, B), so here by majority class A has been predicted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.702046</td>\n",
       "      <td>0.821373</td>\n",
       "      <td>0.822446</td>\n",
       "      <td>0.801306</td>\n",
       "      <td>0.811738</td>\n",
       "      <td>0.820623</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>8.487113</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.812706</td>\n",
       "      <td>0.803754</td>\n",
       "      <td>0.808205</td>\n",
       "      <td>0.816184</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>6.462828</td>\n",
       "      <td>0.826078</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.811710</td>\n",
       "      <td>0.817715</td>\n",
       "      <td>0.825541</td>\n",
       "      <td>{'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2.696353</td>\n",
       "      <td>0.809118</td>\n",
       "      <td>0.808133</td>\n",
       "      <td>0.790494</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.808422</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>3.602068</td>\n",
       "      <td>0.827059</td>\n",
       "      <td>0.824710</td>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.818780</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>{'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 1000, 'max_depth': None, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.75}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Voting Classifier-Hard</td>\n",
       "      <td>6.679722</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.824065</td>\n",
       "      <td>0.813137</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.826255</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Duration  Accuracy  Precision    Recall        F1  \\\n",
       "0     Logistic Regression  0.702046  0.821373   0.822446  0.801306  0.811738   \n",
       "1           Random Forest  8.487113  0.816667   0.812706  0.803754  0.808205   \n",
       "2                AdaBoost  6.462828  0.826078   0.823810  0.811710  0.817715   \n",
       "3                     KNN  2.696353  0.809118   0.808133  0.790494  0.799216   \n",
       "4           XGBClassifier  3.602068  0.827059   0.824710  0.812933  0.818780   \n",
       "5  Voting Classifier-Hard  6.679722  0.826765   0.824065  0.813137  0.818565   \n",
       "\n",
       "        AUC  \\\n",
       "0  0.820623   \n",
       "1  0.816184   \n",
       "2  0.825541   \n",
       "3  0.808422   \n",
       "4  0.826531   \n",
       "5  0.826255   \n",
       "\n",
       "                                                                                                                                             Best Parameters  \n",
       "0                                                                                          {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}  \n",
       "1                          {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}  \n",
       "2                                                              {'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}  \n",
       "3                                                                                     {'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}  \n",
       "4  {'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 1000, 'max_depth': None, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.75}  \n",
       "5                                                                                                                                                             "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# train a voting classifier using the three models (model01, model02, model03)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "#    estimators=[('lr', model01), ('rf', model02), ('ada', model03), ('knn', model04), ('xgb', model05), ('svc', model06)],\n",
    "    estimators=[('lr', model01), ('rf', model02), ('ada', model03), ('knn', model04), ('xgb', model05)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy, precision, recall, f1, auc\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "results.loc[len(results.index)] = ['Voting Classifier-Hard', end-start, accuracy, precision, recall, f1, auc, '']\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting\n",
    "\n",
    "This voting classifier predicts the class label based on the argmax of the sums of the predicted probabilities. Soft voting takes into account the probability of each label. It predicts the class label based on the argmax of the sum of the predicted probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.702046</td>\n",
       "      <td>0.821373</td>\n",
       "      <td>0.822446</td>\n",
       "      <td>0.801306</td>\n",
       "      <td>0.811738</td>\n",
       "      <td>0.820623</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>8.487113</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.812706</td>\n",
       "      <td>0.803754</td>\n",
       "      <td>0.808205</td>\n",
       "      <td>0.816184</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>6.462828</td>\n",
       "      <td>0.826078</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.811710</td>\n",
       "      <td>0.817715</td>\n",
       "      <td>0.825541</td>\n",
       "      <td>{'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2.696353</td>\n",
       "      <td>0.809118</td>\n",
       "      <td>0.808133</td>\n",
       "      <td>0.790494</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.808422</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>3.602068</td>\n",
       "      <td>0.827059</td>\n",
       "      <td>0.824710</td>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.818780</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>{'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 1000, 'max_depth': None, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.75}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Voting Classifier-Hard</td>\n",
       "      <td>6.679722</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.824065</td>\n",
       "      <td>0.813137</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.826255</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Voting Classifier-Soft</td>\n",
       "      <td>6.676889</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.824199</td>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.818527</td>\n",
       "      <td>0.826248</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Duration  Accuracy  Precision    Recall        F1  \\\n",
       "0     Logistic Regression  0.702046  0.821373   0.822446  0.801306  0.811738   \n",
       "1           Random Forest  8.487113  0.816667   0.812706  0.803754  0.808205   \n",
       "2                AdaBoost  6.462828  0.826078   0.823810  0.811710  0.817715   \n",
       "3                     KNN  2.696353  0.809118   0.808133  0.790494  0.799216   \n",
       "4           XGBClassifier  3.602068  0.827059   0.824710  0.812933  0.818780   \n",
       "5  Voting Classifier-Hard  6.679722  0.826765   0.824065  0.813137  0.818565   \n",
       "6  Voting Classifier-Soft  6.676889  0.826765   0.824199  0.812933  0.818527   \n",
       "\n",
       "        AUC  \\\n",
       "0  0.820623   \n",
       "1  0.816184   \n",
       "2  0.825541   \n",
       "3  0.808422   \n",
       "4  0.826531   \n",
       "5  0.826255   \n",
       "6  0.826248   \n",
       "\n",
       "                                                                                                                                             Best Parameters  \n",
       "0                                                                                          {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}  \n",
       "1                          {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}  \n",
       "2                                                              {'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}  \n",
       "3                                                                                     {'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}  \n",
       "4  {'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 1000, 'max_depth': None, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.75}  \n",
       "5                                                                                                                                                             \n",
       "6                                                                                                                                                             "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# train a voting classifier using the three models (model01, model02, model03, model04, model05, model06)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "#    estimators=[('lr', model01), ('rf', model02), ('ada', model03), ('knn', model04), ('xgb', model05), ('svc', model06)],\n",
    "    estimators=[('lr', model01), ('rf', model02), ('ada', model03), ('knn', model04), ('xgb', model05)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy, precision, recall, f1, auc\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "results.loc[len(results.index)] = ['Voting Classifier-Soft', end-start, accuracy, precision, recall, f1, auc, '']\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a StackedClassifier with the above models (minus the VotingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.702046</td>\n",
       "      <td>0.821373</td>\n",
       "      <td>0.822446</td>\n",
       "      <td>0.801306</td>\n",
       "      <td>0.811738</td>\n",
       "      <td>0.820623</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>8.487113</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.812706</td>\n",
       "      <td>0.803754</td>\n",
       "      <td>0.808205</td>\n",
       "      <td>0.816184</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>6.462828</td>\n",
       "      <td>0.826078</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.811710</td>\n",
       "      <td>0.817715</td>\n",
       "      <td>0.825541</td>\n",
       "      <td>{'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2.696353</td>\n",
       "      <td>0.809118</td>\n",
       "      <td>0.808133</td>\n",
       "      <td>0.790494</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.808422</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>3.602068</td>\n",
       "      <td>0.827059</td>\n",
       "      <td>0.824710</td>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.818780</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>{'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 1000, 'max_depth': None, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.75}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Voting Classifier-Hard</td>\n",
       "      <td>6.679722</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.824065</td>\n",
       "      <td>0.813137</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.826255</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Voting Classifier-Soft</td>\n",
       "      <td>6.676889</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.824199</td>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.818527</td>\n",
       "      <td>0.826248</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stacking Classifier</td>\n",
       "      <td>32.927035</td>\n",
       "      <td>0.827647</td>\n",
       "      <td>0.825736</td>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.819285</td>\n",
       "      <td>0.827097</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model   Duration  Accuracy  Precision    Recall        F1  \\\n",
       "0     Logistic Regression   0.702046  0.821373   0.822446  0.801306  0.811738   \n",
       "1           Random Forest   8.487113  0.816667   0.812706  0.803754  0.808205   \n",
       "2                AdaBoost   6.462828  0.826078   0.823810  0.811710  0.817715   \n",
       "3                     KNN   2.696353  0.809118   0.808133  0.790494  0.799216   \n",
       "4           XGBClassifier   3.602068  0.827059   0.824710  0.812933  0.818780   \n",
       "5  Voting Classifier-Hard   6.679722  0.826765   0.824065  0.813137  0.818565   \n",
       "6  Voting Classifier-Soft   6.676889  0.826765   0.824199  0.812933  0.818527   \n",
       "7     Stacking Classifier  32.927035  0.827647   0.825736  0.812933  0.819285   \n",
       "\n",
       "        AUC  \\\n",
       "0  0.820623   \n",
       "1  0.816184   \n",
       "2  0.825541   \n",
       "3  0.808422   \n",
       "4  0.826531   \n",
       "5  0.826255   \n",
       "6  0.826248   \n",
       "7  0.827097   \n",
       "\n",
       "                                                                                                                                             Best Parameters  \n",
       "0                                                                                          {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}  \n",
       "1                          {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}  \n",
       "2                                                              {'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}  \n",
       "3                                                                                     {'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}  \n",
       "4  {'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 1000, 'max_depth': None, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.75}  \n",
       "5                                                                                                                                                             \n",
       "6                                                                                                                                                             \n",
       "7                                                                                                                                                             "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# train a stacking classifier using the three models (model01, model02, model03)\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "#    estimators=[('lr', model01), ('rf', model02), ('ada', model03), ('knn', model04), ('xgb', model05), ('svc', model06)],\n",
    "    estimators=[('lr', model01), ('rf', model02), ('ada', model03), ('knn', model04), ('xgb', model05)],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy, precision, recall, f1, auc\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "results.loc[len(results.index)] = ['Stacking Classifier', end-start, accuracy, precision, recall, f1, auc, '']\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discuss the results of the models and the best model based on F1 score results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.702046</td>\n",
       "      <td>0.821373</td>\n",
       "      <td>0.822446</td>\n",
       "      <td>0.801306</td>\n",
       "      <td>0.811738</td>\n",
       "      <td>0.820623</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>8.487113</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.812706</td>\n",
       "      <td>0.803754</td>\n",
       "      <td>0.808205</td>\n",
       "      <td>0.816184</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>6.462828</td>\n",
       "      <td>0.826078</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.811710</td>\n",
       "      <td>0.817715</td>\n",
       "      <td>0.825541</td>\n",
       "      <td>{'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2.696353</td>\n",
       "      <td>0.809118</td>\n",
       "      <td>0.808133</td>\n",
       "      <td>0.790494</td>\n",
       "      <td>0.799216</td>\n",
       "      <td>0.808422</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>3.602068</td>\n",
       "      <td>0.827059</td>\n",
       "      <td>0.824710</td>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.818780</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>{'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 1000, 'max_depth': None, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.75}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Voting Classifier-Hard</td>\n",
       "      <td>6.679722</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.824065</td>\n",
       "      <td>0.813137</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.826255</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Voting Classifier-Soft</td>\n",
       "      <td>6.676889</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.824199</td>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.818527</td>\n",
       "      <td>0.826248</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stacking Classifier</td>\n",
       "      <td>32.927035</td>\n",
       "      <td>0.827647</td>\n",
       "      <td>0.825736</td>\n",
       "      <td>0.812933</td>\n",
       "      <td>0.819285</td>\n",
       "      <td>0.827097</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model   Duration  Accuracy  Precision    Recall        F1  \\\n",
       "0     Logistic Regression   0.702046  0.821373   0.822446  0.801306  0.811738   \n",
       "1           Random Forest   8.487113  0.816667   0.812706  0.803754  0.808205   \n",
       "2                AdaBoost   6.462828  0.826078   0.823810  0.811710  0.817715   \n",
       "3                     KNN   2.696353  0.809118   0.808133  0.790494  0.799216   \n",
       "4           XGBClassifier   3.602068  0.827059   0.824710  0.812933  0.818780   \n",
       "5  Voting Classifier-Hard   6.679722  0.826765   0.824065  0.813137  0.818565   \n",
       "6  Voting Classifier-Soft   6.676889  0.826765   0.824199  0.812933  0.818527   \n",
       "7     Stacking Classifier  32.927035  0.827647   0.825736  0.812933  0.819285   \n",
       "\n",
       "        AUC  \\\n",
       "0  0.820623   \n",
       "1  0.816184   \n",
       "2  0.825541   \n",
       "3  0.808422   \n",
       "4  0.826531   \n",
       "5  0.826255   \n",
       "6  0.826248   \n",
       "7  0.827097   \n",
       "\n",
       "                                                                                                                                             Best Parameters  \n",
       "0                                                                                          {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.6280291441834259}  \n",
       "1                          {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': True}  \n",
       "2                                                              {'n_estimators': 500, 'learning_rate': 0.1, 'estimator': DecisionTreeClassifier(max_depth=2)}  \n",
       "3                                                                                     {'weights': 'uniform', 'p': 2, 'n_neighbors': 11, 'algorithm': 'auto'}  \n",
       "4  {'subsample': 1.0, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 1000, 'max_depth': None, 'learning_rate': 0.01, 'gamma': 1, 'colsample_bytree': 0.75}  \n",
       "5                                                                                                                                                             \n",
       "6                                                                                                                                                             \n",
       "7                                                                                                                                                             "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_csv('results.csv', index=False)     \n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
