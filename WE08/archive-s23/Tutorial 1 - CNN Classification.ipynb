{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1 - CNN Classification - Keras - Working with image files\n",
    "\n",
    "We will predict the category of a fruit image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4844 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image Data Generator manipulates and \"augments\" images\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "\n",
    "# Directory Iterator reads images from a directory\n",
    "\n",
    "train_data = DirectoryIterator(\n",
    "    directory=\"FRUITS/Training_10\",\n",
    "    image_data_generator = train_datagen,\n",
    "    target_size=(32, 32),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=100,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1619 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "valid_data = DirectoryIterator(\n",
    "    directory=\"FRUITS/Test_10\",\n",
    "    image_data_generator = valid_datagen,\n",
    "    target_size=(16, 16),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=100,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Default options for Conv2D:\n",
    "\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters, kernel_size, strides=(1, 1), padding='valid',\n",
    "    data_format=None, dilation_rate=(1, 1), groups=1, activation=None,\n",
    "    use_bias=True, kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros', kernel_regularizer=None,\n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n",
    "    bias_constraint=None, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 16, 16, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 8, 8, 16)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8, 8, 16)          0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 3, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3, 3, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               36992     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,370\n",
      "Trainable params: 43,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', \n",
    "                 input_shape=(16,16,3)))\n",
    "\n",
    "#model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "#model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "#### FIXED!!!!!!!\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# initiate adam optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "49/49 [==============================] - 45s 897ms/step - loss: 1.2551 - accuracy: 0.5279 - val_loss: 0.3735 - val_accuracy: 0.9024\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.4555 - accuracy: 0.8293 - val_loss: 0.2682 - val_accuracy: 0.9154\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 5s 104ms/step - loss: 0.3266 - accuracy: 0.8852 - val_loss: 0.3738 - val_accuracy: 0.8116\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 5s 102ms/step - loss: 0.1627 - accuracy: 0.9420 - val_loss: 0.1921 - val_accuracy: 0.9055\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 5s 109ms/step - loss: 0.1393 - accuracy: 0.9505 - val_loss: 0.1032 - val_accuracy: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19f3bc1fd00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_data,\n",
    "        epochs=5,\n",
    "        validation_data=valid_data,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19f3efddf10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "img = load_img(\"FRUITS/Test_10/Apple Red 1/3_100.jpg\",\n",
    "               color_mode='rgb',\n",
    "               target_size=(16,16)\n",
    "              )\n",
    "\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3701964e-06, 5.9523654e-07, 3.2563743e-09, 7.8031592e-10,\n",
       "        1.2196672e-07, 9.8319107e-01, 7.1806835e-07, 1.8809624e-05,\n",
       "        1.6786395e-02, 1.9346379e-08]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the image to array\n",
    "single_image = img_to_array(img)\n",
    "\n",
    "#Also divide the image values by 255 to normalize\n",
    "img_rank4 = np.expand_dims(single_image/255, axis=0)\n",
    "\n",
    "model.predict(img_rank4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.98, 0.  , 0.  , 0.02, 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(img_rank4),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can predict the class directly using the following function:\n",
    "\n",
    "np.argmax(model.predict(img_rank4), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple Braeburn': 0,\n",
       " 'Apple Golden 1': 1,\n",
       " 'Apple Golden 2': 2,\n",
       " 'Apple Golden 3': 3,\n",
       " 'Apple Granny Smith': 4,\n",
       " 'Apple Red 1': 5,\n",
       " 'Apple Red 2': 6,\n",
       " 'Apple Red 3': 7,\n",
       " 'Apple Red Delicious': 8,\n",
       " 'Apple Red Yellow': 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can retrieve the class labels from the train_generator:\n",
    "\n",
    "label_map = (train_data.class_indices)\n",
    "\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple Red 1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can retrieve the class label of the prediction:\n",
    "\n",
    "list(label_map.keys())[np.argmax(model.predict(img_rank4), axis=-1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
